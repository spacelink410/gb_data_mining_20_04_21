"""
В скрипте в переменную ig_users необходимо поместить требуемых пользователей

Парсер начнет работу спарсит этих пользователей их подписки
подписчиков и найдет взаимоподписанных пользователей - рукопожатия.

Далее по pipeline сохранит данные в базе данных. При этом будет не генерировать
новые записи, а обновлять старые.

Так же система проверит, являются ли пользователи взаимоподписанными и если да,
то остановит парсер и выдаст сообщение.

Если пользователи не взаимоподписанные, то паук начнет парсить всех друзей и писать
их  базу. А так же друзей друзей и т.д.

После каждой записи нового пользоватедя в базу по pipeline система будет искать цепочки
между пользователями. Искать цепочки будем черех агрегатор $graphLookup. Он позволяет
средствавми базы, в случае, если есть взаимосвязь найти цепочки и сказать, сколько
узлов между пользователями. Как только такой агрегатор найдет связь, останавливаем парсинг
и запускаем метод поиска цепочки.

Поиск цепочки происходит при помощи того же $graphLookup, только циклично уменьшая узлы
графа путем перемещения по друзьям пользователей, до тех пор, пока количество узлов между
пользователями не станет равным 0.

Результат поиска выводится в файл out в виде словаря следующего формата:
{'узел искомого первого пользователя': ['узел первой связи'],
'узел первой связи': ['узел второй связи'],
'узел второй связи': ['узел искомого второго пользователя']}

Пример: {'_anakart_': ['spacelink410'], 'spacelink410': ['vladimir_tarasyuk'], 'vladimir_tarasyuk': ['mari.tarasyuk']}

Если пользователями являются друзьями, то будет следующая запись:
Пользователь {user1} является другом {user2}

Кроме этого, паук хранит cookie в памяти, чтобы каждый раз не делать авторизацию, а брать
сессию из памяти. Instagram очень сильно раздражается от постоянных логинов.

Выходные файлы приложены к проекту. (out и out_2)

К проекту приложен фрагмент базы данных mongodb для быстрого тестирования поиска
связей. (ig_IgParseItem.json.zip)
"""

import os
import dotenv
from scrapy.crawler import CrawlerProcess
from scrapy.settings import Settings
from ig_parse.spiders.ig import IgSpider

# from pymongo import MongoClient

if __name__ == '__main__':
    dotenv.load_dotenv('.env')
    crawler_settings = Settings()
    crawler_settings.setmodule('ig_parse.settings')
    crawler_process = CrawlerProcess(settings=crawler_settings)
    # Пользователи для тестирования
    # для поиска цепочек разной длины -----------------------------
    # '_anakart_', 'mari.tarasyuk', 'valeria.0901', 'spacelink410',
    # 'vladimir_tarasyuk', 'ilya.tkachev410'
    # --------------------------------------------------------------
    # закрытый аккаунт 'besplatno_khv',
    # --------------------------------------------------------------
    # несуществующий пользователь '123'
    # --------------------------------------------------------------
    ig_users = ['_anakart_', 'mari.tarasyuk']

    if len(ig_users) != 2:
        print("Должно быть 2 пользователя")
    else:
        crawler_process.crawl(
            IgSpider,
            login=os.getenv('INST_LOGIN'),
            password=os.getenv('INST_PSWORD'),
            ig_users=ig_users,
        )
        crawler_process.start()
